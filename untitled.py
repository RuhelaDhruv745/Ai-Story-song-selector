# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zF6FHoUV1_PShi-PKaJTiLMaJAayDY6F
"""



!pip install transformers torch pillow

"""First, let's import the necessary libraries. We'll need `CLIPProcessor` and `CLIPModel` from the `transformers` library, and `Image` from `PIL` to handle images."""

from transformers import CLIPProcessor, CLIPModel
from PIL import Image
import torch

"""Now, let's load a pre-trained CLIP model and its corresponding processor. We'll use the `openai/clip-vit-base-patch32` model, which is a good balance of performance and size."""

model = CLIPModel.from_pretrained("openai/clip-vit-base-patch32")
processor = CLIPProcessor.from_pretrained("openai/clip-vit-base-patch32")

"""Next, let's define the categories or labels we want to classify our image into. These will be used as text inputs for the CLIP model."""

candidate_labels = ["a photo of a cat", "a photo of a dog", "a photo of a bird", "a photo of a car", "a photo of a house"]

"""Now, we need an image to classify. For demonstration purposes, I'll provide an example image URL. You can replace this with your own image by uploading it to Colab and providing its path, or by using another URL."""

import requests
from io import BytesIO

# Example image URL (a cat)
image_url = "http://images.cocodataset.org/val2017/000000039769.jpg"
response = requests.get(image_url)
image = Image.open(BytesIO(response.content))

# Display the image
image

"""With the image and candidate labels ready, we can now process them using the `CLIPProcessor` and then pass them to the model to get the image and text embeddings. Finally, we'll calculate the similarity to determine the classification."""

inputs = processor(text=candidate_labels, images=image, return_tensors="pt", padding=True)

with torch.no_grad():
    outputs = model(**inputs)

logits_per_image = outputs.logits_per_image # this is the image-text similarity score
probs = logits_per_image.softmax(dim=1) # we can take the softmax to get probabilities

# Get the predicted label
predicted_index = torch.argmax(probs).item()
predicted_label = candidate_labels[predicted_index]
confidence = probs[0, predicted_index].item()

print(f"The image is classified as: '{predicted_label}' with a confidence of {confidence:.2f}")

# Copy and paste this into a Google Colab cell
!pip install transformers pillow torch

from transformers import pipeline
from PIL import Image
import requests

# 1. Load the "Eyes" of your AI
classifier = pipeline("zero-shot-image-classification", model="openai/clip-vit-base-patch32")

# 2. Pick an image (You can replace this URL with a link to your own photo)
url = "https://images.unsplash.com/photo-1501785888041-af3ef285b470" # A scenic sunset
image = Image.open(requests.get(url, stream=True).raw)

# 3. Define the "Vibes" you want to check for
candidate_labels = ["vintage aesthetic", "high energy party", "calm nature", "sad lo-fi", "trendy cinematic"]

# 4. Run the AI
results = classifier(image, candidate_labels=candidate_labels)

# 5. See what the AI thinks
print(f"Top Vibe: {results[0]['label']} ({round(results[0]['score']*100)}% match)")

# Step 2: Create the Song Database
song_database = [
    {"title": "The Fate of Ophelia", "artist": "Taylor Swift", "vibe": "trendy cinematic"},
    {"title": "Golden", "artist": "Huntrix", "vibe": "high energy party"},
    {"title": "Ordinary", "artist": "Alex Warren", "vibe": "sad lo-fi"},
    {"title": "Man I Need", "artist": "Olivia Dean", "vibe": "calm nature"},
    {"title": "Last Christmas", "artist": "Wham!", "vibe": "vintage aesthetic"},
    {"title": "Iris", "artist": "Goo Goo Dolls", "vibe": "vintage aesthetic"},
    {"title": "Espresso", "artist": "Sabrina Carpenter", "vibe": "high energy party"},
]

# Simple matching function
def get_song_recommendation(ai_detected_vibe):
    # Search the database for songs that match the vibe
    matches = [s for s in song_database if s['vibe'] == ai_detected_vibe]

    if matches:
        print(f"--- AI Recommendation for '{ai_detected_vibe}' ---")
        for song in matches:
            print(f"ðŸŽµ {song['title']} by {song['artist']}")
    else:
        print("No exact match found. Try adding more songs to your database!")

# Example usage (using the result from our Step 1 CLIP model):
detected_vibe = "vintage aesthetic" # This would come from your CLIP code
get_song_recommendation(detected_vibe)

!pip install streamlit
import streamlit as st
from transformers import pipeline
from PIL import Image

# --- APP SETUP ---
st.set_page_config(page_title="AI Story Matcher", page_icon="ðŸŽµ")
st.title("ðŸŽµ Instagram Story Vibe Matcher")
st.write("Upload a photo, and I'll find the best trending song for your story.")

# --- LOAD AI MODELS ---
@st.cache_resource # This keeps the AI "awake" so it doesn't reload every time
def load_ai():
    return pipeline("zero-shot-image-classification", model="openai/clip-vit-base-patch32")

classifier = load_ai()

# --- THE SONG DATABASE ---
song_database = [
    {"title": "The Fate of Ophelia", "artist": "Taylor Swift", "vibe": "trendy cinematic"},
    {"title": "Golden", "artist": "Huntrix", "vibe": "high energy party"},
    {"title": "Ordinary", "artist": "Alex Warren", "vibe": "sad lo-fi"},
    {"title": "Man I Need", "artist": "Olivia Dean", "vibe": "calm nature"},
    {"title": "Last Christmas", "artist": "Wham!", "vibe": "vintage aesthetic"},
    {"title": "Espresso", "artist": "Sabrina Carpenter", "vibe": "high energy party"}
]
vibes = ["vintage aesthetic", "high energy party", "calm nature", "sad lo-fi", "trendy cinematic"]

# --- THE INTERFACE ---
uploaded_file = st.file_uploader("Choose a photo...", type=["jpg", "png", "jpeg"])

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.image(image, caption='Your Upload', use_column_width=True)

    with st.spinner('Analyzing the vibe...'):
        # 1. Analyze Image
        results = classifier(image, candidate_labels=vibes)
        top_vibe = results[0]['label']

        # 2. Match Song
        matches = [s for s in song_database if s['vibe'] == top_vibe]

    st.success(f"Detected Vibe: **{top_vibe}**")
    st.subheader("Recommended Songs for your Story:")
    for song in matches:
        st.write(f"ðŸŽ§ **{song['title']}** - {song['artist']}")